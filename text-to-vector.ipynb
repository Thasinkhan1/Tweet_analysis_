{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:56:23.344094Z",
     "iopub.status.busy": "2025-01-16T05:56:23.343619Z",
     "iopub.status.idle": "2025-01-16T05:56:23.350674Z",
     "shell.execute_reply": "2025-01-16T05:56:23.349019Z",
     "shell.execute_reply.started": "2025-01-16T05:56:23.344056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from contractions import contractions_dict\n",
    "import contractions\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en import STOP_WORDS as spacy_stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\",disable=[\"ner\",\"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combined_stopwords = set(stopwords.words('english')).union(set(spacy_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "                  encoding=\"latin-1\",header=None,names=[\"sentiment\",\"id\",\"date\",\"flag\",\"username\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.drop(labels=data.columns[1:5],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(tweet):\n",
    "\n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(pool.map(normalize_tweet,data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fix_contractions(tweet): #For example I’ll be there within 5 min. Are u not gng there? Am I mssng out on smthng? I’d like to see u near d park.\n",
    "\n",
    "    return contractions.fix(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(pool.map(fix_contractions,data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_noisy_tokens(tweet):\n",
    "\n",
    "    return re.sub(pattern=r'@[a-zA-Z0-9 ]+|#[a-zA-Z0-9 ]+|\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*|\\W+|\\d+|<(\"[^\"]*\"|\\'[^\\']*\\'|[^\\'\">])*>|_+|[^\\u0000-\\u007f]+',\n",
    "                 string=tweet,repl=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(pool.map(remove_noisy_tokens,data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_remaining_noisy_tokens(tweet):\n",
    "\n",
    "    return re.sub(pattern=r'\\b\\w\\b|[^\\u0000-\\u007f]+|_+|\\W+',\n",
    "                 string=tweet,repl=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(pool.map(remove_remaining_noisy_tokens,data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(pool.map(word_tokenize,data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def is_stopword(token):\n",
    "\n",
    "    return token not in combined_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_tweet):\n",
    "\n",
    "    return [token for token in tokenized_tweet if is_stopword(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(pool.map(remove_stopwords,data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"stopwords_removed.pkl\",\"wb\") as file_handle:\n",
    "    pickle.dump(data[\"text\"],file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tokenized_tweet):\n",
    "\n",
    "    raw_tweet = \" \".join(tokenized_tweet)\n",
    "    doc = nlp(raw_tweet)\n",
    "    lemmatized_tweet = list()\n",
    "\n",
    "    for token in doc:\n",
    "        lemmatized_tweet.append(token.lemma_)\n",
    "\n",
    "    return lemmatized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n",
    "\n",
    "    data[\"text\"] = list(tqdm(pool.map(lemmatize_tweet,data[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"lemmatized_tweets.pkl\",\"wb\") as file_handle:\n",
    "    pickle.dump(data[\"text\"],file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:34.967493Z",
     "iopub.status.busy": "2025-01-16T05:04:34.966717Z",
     "iopub.status.idle": "2025-01-16T05:04:41.590671Z",
     "shell.execute_reply": "2025-01-16T05:04:41.588594Z",
     "shell.execute_reply.started": "2025-01-16T05:04:34.967447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "with open(\"/kaggle/input/lemmantized-data/lemmatized_tweets.pkl\",\"rb\") as file_handle:\n",
    "    data[\"text\"] = pickle.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:44.245028Z",
     "iopub.status.busy": "2025-01-16T05:04:44.244581Z",
     "iopub.status.idle": "2025-01-16T05:04:44.331668Z",
     "shell.execute_reply": "2025-01-16T05:04:44.330241Z",
     "shell.execute_reply.started": "2025-01-16T05:04:44.244992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481742                                       [like, dreamy]\n",
       "606693                        [ugh, dream, mind, want, hard]\n",
       "308846                  [hello, hello, feel, prepared, exam]\n",
       "134335                                                    []\n",
       "1078077    [plan, concert, philippine, summer, tour, way,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:47.506968Z",
     "iopub.status.busy": "2025-01-16T05:04:47.506542Z",
     "iopub.status.idle": "2025-01-16T05:04:48.237337Z",
     "shell.execute_reply": "2025-01-16T05:04:48.236156Z",
     "shell.execute_reply.started": "2025-01-16T05:04:47.506933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "converted_raw_text = list(data[\"text\"].apply(lambda x: \" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:48.239274Z",
     "iopub.status.busy": "2025-01-16T05:04:48.238915Z",
     "iopub.status.idle": "2025-01-16T05:04:48.441060Z",
     "shell.execute_reply": "2025-01-16T05:04:48.440011Z",
     "shell.execute_reply.started": "2025-01-16T05:04:48.239242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "converted_raw_text = list(filter(lambda x: len(x) > 0,converted_raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:48.443720Z",
     "iopub.status.busy": "2025-01-16T05:04:48.443348Z",
     "iopub.status.idle": "2025-01-16T05:04:48.450149Z",
     "shell.execute_reply": "2025-01-16T05:04:48.448964Z",
     "shell.execute_reply.started": "2025-01-16T05:04:48.443689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408026"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:48.577753Z",
     "iopub.status.busy": "2025-01-16T05:04:48.577412Z",
     "iopub.status.idle": "2025-01-16T05:04:50.816357Z",
     "shell.execute_reply": "2025-01-16T05:04:50.815076Z",
     "shell.execute_reply.started": "2025-01-16T05:04:48.577718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for cleaned_tweet in converted_raw_text:\n",
    "    vocab.update(set(cleaned_tweet.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T02:31:35.819125Z",
     "iopub.status.busy": "2025-01-10T02:31:35.818837Z",
     "iopub.status.idle": "2025-01-10T02:31:35.824865Z",
     "shell.execute_reply": "2025-01-10T02:31:35.823786Z",
     "shell.execute_reply.started": "2025-01-10T02:31:35.819099Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273488"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:04:52.586635Z",
     "iopub.status.busy": "2025-01-16T05:04:52.586149Z",
     "iopub.status.idle": "2025-01-16T05:05:05.396198Z",
     "shell.execute_reply": "2025-01-16T05:05:05.394928Z",
     "shell.execute_reply.started": "2025-01-16T05:04:52.586587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_text = vectorizer.fit_transform(converted_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:05.397765Z",
     "iopub.status.busy": "2025-01-16T05:05:05.397447Z",
     "iopub.status.idle": "2025-01-16T05:05:05.404502Z",
     "shell.execute_reply": "2025-01-16T05:05:05.403105Z",
     "shell.execute_reply.started": "2025-01-16T05:05:05.397738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408026, 273469)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:05.406512Z",
     "iopub.status.busy": "2025-01-16T05:05:05.406196Z",
     "iopub.status.idle": "2025-01-16T05:05:08.556476Z",
     "shell.execute_reply": "2025-01-16T05:05:08.555227Z",
     "shell.execute_reply.started": "2025-01-16T05:05:05.406484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cumulative_tfs = Counter()\n",
    "for cleaned_tweet in data[\"text\"]:\n",
    "\n",
    "    cumulative_tfs.update(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:17.131364Z",
     "iopub.status.busy": "2025-01-16T05:05:17.131043Z",
     "iopub.status.idle": "2025-01-16T05:05:17.294569Z",
     "shell.execute_reply": "2025-01-16T05:05:17.293409Z",
     "shell.execute_reply.started": "2025-01-16T05:05:17.131338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "most_frequent_tokens = cumulative_tfs.most_common(30000)\n",
    "most_frequent_tokens = dict(most_frequent_tokens)\n",
    "truncated_vocab = list(most_frequent_tokens.keys())\n",
    "\n",
    "truncated_vocab2idx = dict(zip(truncated_vocab,range(len(truncated_vocab)))) #indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:17.468419Z",
     "iopub.status.busy": "2025-01-16T05:05:17.468050Z",
     "iopub.status.idle": "2025-01-16T05:05:17.474490Z",
     "shell.execute_reply": "2025-01-16T05:05:17.473337Z",
     "shell.execute_reply.started": "2025-01-16T05:05:17.468383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truncated_vocab2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:20.651976Z",
     "iopub.status.busy": "2025-01-16T05:05:20.651575Z",
     "iopub.status.idle": "2025-01-16T05:05:31.615094Z",
     "shell.execute_reply": "2025-01-16T05:05:31.613465Z",
     "shell.execute_reply.started": "2025-01-16T05:05:20.651944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:1380: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=truncated_vocab2idx)\n",
    "truncated_tfidf_matrix = vectorizer.fit_transform(converted_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:31.617089Z",
     "iopub.status.busy": "2025-01-16T05:05:31.616626Z",
     "iopub.status.idle": "2025-01-16T05:05:31.624254Z",
     "shell.execute_reply": "2025-01-16T05:05:31.622946Z",
     "shell.execute_reply.started": "2025-01-16T05:05:31.617042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408026, 30000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVD = U.^.U.T</h1>\n",
    "<h4>U and v.T is Orthogonal matrix and ^/sigma is a diagnal matrix</h4>\n",
    "<h4>having in a U matrix value is called eigen value and U and V are unitary it means U*U.T = U.T * U = identity matrix</h4>\n",
    "<h4>same thing with V,  V*V.T = V.T * V = identity</h4>\n",
    "<h4>Sigma is the diagnal matrix sigam1 >= sigma2 >= sigma3 >= sigma_n >= 0</h4>\n",
    "<h2>U is called Left singular vector and V is called right singular vectors and sigma is called is sigular value sigma values ordered by importance </h2>\n",
    "\n",
    "<h2>V.T is a word embeding matrix</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# left_singular_U => A*A.T - lamda * identity matrix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:05:38.643490Z",
     "iopub.status.busy": "2025-01-16T05:05:38.642992Z",
     "iopub.status.idle": "2025-01-16T05:06:30.429354Z",
     "shell.execute_reply": "2025-01-16T05:06:30.428061Z",
     "shell.execute_reply.started": "2025-01-16T05:05:38.643442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=64) # Reduce to 64 dimensions\n",
    "svd.fit(truncated_tfidf_matrix)\n",
    "U_k = svd.transform(truncated_tfidf_matrix)\n",
    "V_k = svd.components_\n",
    "S = svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T04:25:41.898701Z",
     "iopub.status.busy": "2025-01-09T04:25:41.897952Z",
     "iopub.status.idle": "2025-01-09T04:25:41.904265Z",
     "shell.execute_reply": "2025-01-09T04:25:41.903082Z",
     "shell.execute_reply.started": "2025-01-09T04:25:41.898511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# S_k = np.sqrt(svd.explained_variance_ * (vectorized_text.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:06:30.431404Z",
     "iopub.status.busy": "2025-01-16T05:06:30.431099Z",
     "iopub.status.idle": "2025-01-16T05:06:30.439198Z",
     "shell.execute_reply": "2025-01-16T05:06:30.437209Z",
     "shell.execute_reply.started": "2025-01-16T05:06:30.431377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1408026, 64), (64, 30000), (64,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_k.shape, V_k.shape, S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T05:53:35.770255Z",
     "iopub.status.busy": "2025-01-16T05:53:35.769493Z",
     "iopub.status.idle": "2025-01-16T05:53:36.040125Z",
     "shell.execute_reply": "2025-01-16T05:53:36.038928Z",
     "shell.execute_reply.started": "2025-01-16T05:53:35.770205Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 1: work, day, good, go, get, today, want, quot, like, time, love, feel, miss, home, morning\n",
      "Topic: 2: work, want, get, tomorrow, ready, hour, today, home, tired, till, hard, bored, early, weekend, ugh\n",
      "Topic: 3: quot, work, want, love, know, like, lol, get, watch, think, miss, new, say, song, amp\n",
      "Topic: 4: good, quot, work, morning, day, luck, night, world, afternoon, mood, sound, say, beautiful, monday, news\n",
      "Topic: 5: day, quot, happy, today, great, mother, school, long, beautiful, nice, enjoy, father, sunny, rainy, bad\n",
      "Topic: 6: want, day, love, know, lol, like, thank, bad, home, happy, feel, come, new, get, mother\n",
      "Topic: 7: love, miss, work, thank, lt, lol, twitter, guy, song, new, friend, happy, get, ya, amp\n",
      "Topic: 8: miss, want, good, day, quot, work, morning, home, friend, baby, leave, school, luck, boyfriend, talk\n",
      "Topic: 9: like, get, feel, lol, know, well, miss, look, thank, time, think, sick, bad, today, hope\n",
      "Topic: 10: get, home, ready, time, night, sleep, new, tomorrow, morning, wait, twitter, finally, bed, early, school\n",
      "Topic: 11: thank, lol, know, follow, time, twitter, great, let, think, god, tweet, need, work, follower, come\n",
      "Topic: 12: lol, know, time, think, twitter, day, let, need, work, haha, try, sorry, thing, right, tweet\n",
      "Topic: 13: know, let, think, get, twitter, sad, day, people, thing, good, need, find, mean, happen, sorry\n",
      "Topic: 14: time, sleep, night, like, bed, great, long, need, tomorrow, watch, think, hour, wait, come, fun\n",
      "Topic: 15: today, time, think, sad, come, know, great, wish, hope, fun, need, bad, rain, birthday, weather\n",
      "Topic: 16: sleep, feel, night, well, tired, need, bad, sick, hour, hope, wake, bed, tomorrow, know, lol\n",
      "Topic: 17: feel, home, time, well, hope, go, lol, sick, bad, come, soon, sad, know, great, thank\n",
      "Topic: 18: home, come, night, like, wish, wait, sleep, know, look, today, way, find, fun, need, tomorrow\n",
      "Topic: 19: think, home, come, feel, need, sick, well, wait, sad, way, twitter, find, hope, bad, new\n",
      "Topic: 20: twitter, hope, new, come, wait, need, well, wish, great, sad, fun, friend, follow, soon, amp\n",
      "Topic: 21: twitter, home, sleep, morning, feel, time, need, day, go, follow, try, hour, love, sick, hate\n",
      "Topic: 22: night, twitter, sad, feel, fun, home, bed, watch, today, great, day, think, bad, movie, know\n",
      "Topic: 23: sad, wish, watch, wait, need, movie, happy, feel, amp, right, new, bad, make, come, leave\n",
      "Topic: 24: wish, happy, twitter, night, think, luck, birthday, feel, get, right, fun, come, bed, want, mother\n",
      "Topic: 25: sad, hope, sleep, morning, wish, home, happy, great, twitter, think, like, make, well, leave, weekend\n",
      "Topic: 26: morning, wait, come, tomorrow, school, feel, early, wake, bed, week, twitter, think, monday, rain, hate\n",
      "Topic: 27: morning, need, tomorrow, happy, night, wish, school, great, bed, early, home, birthday, wake, hate, leave\n",
      "Topic: 28: watch, morning, movie, amp, home, great, wait, tv, new, happy, hope, tonight, award, mtv, way\n",
      "Topic: 29: wait, tomorrow, look, school, new, wish, good, week, forward, sleep, home, long, well, exam, leave\n",
      "Topic: 30: happy, birthday, mother, wait, amp, lt, new, sleep, mom, friend, feel, go, good, make, hour\n",
      "Topic: 31: tomorrow, watch, come, school, happy, need, hope, bed, twitter, like, well, soon, time, think, good\n",
      "Topic: 32: bad, tomorrow, look, amp, sorry, school, forward, happy, come, thing, watch, hate, rain, hurt, way\n",
      "Topic: 33: fun, wait, haha, amp, lt, like, tonight, morning, lot, sound, school, friend, guy, hate, need\n",
      "Topic: 34: bad, sorry, hope, wait, night, like, happy, hurt, hear, soon, home, watch, morning, hate, suck\n",
      "Topic: 35: amp, sorry, lt, night, like, follow, well, bed, day, people, tweet, hear, tired, try, rain\n",
      "Topic: 36: sorry, great, hear, tweet, look, fun, watch, guy, feel, lt, new, come, morning, sleep, forward\n",
      "Topic: 37: new, look, well, morning, night, forward, com, bed, day, nice, feel, time, twitpic, hope, phone\n",
      "Topic: 38: rain, hate, look, wait, right, need, sick, forward, twitter, nice, well, oh, night, week, away\n",
      "Topic: 39: lt, look, wait, need, haha, gt, forward, well, morning, twitter, bad, com, tonight, bed, talk\n",
      "Topic: 40: lt, new, rain, hate, school, way, haha, week, right, gt, friend, sick, start, nice, follow\n",
      "Topic: 41: week, haha, way, school, right, com, leave, nice, tweet, follow, well, friend, twitpic, night, try\n",
      "Topic: 42: week, school, lt, leave, look, weekend, night, watch, twitter, forward, start, soon, sick, ready, summer\n",
      "Topic: 43: hate, right, bed, sick, friend, tired, people, hope, look, hurt, come, wake, ugh, long, great\n",
      "Topic: 44: way, right, nice, follow, rain, tomorrow, oh, well, wait, try, help, early, tonight, bored, find\n",
      "Topic: 45: right, week, rain, tired, bed, new, leave, home, suck, haha, twitter, fun, bored, yes, away\n",
      "Topic: 46: bed, tired, way, haha, hurt, sick, wake, head, twitter, weekend, hour, early, week, new, hope\n",
      "Topic: 47: com, follow, tweet, bed, twitpic, tired, nice, people, week, rain, add, pay, train, www, try\n",
      "Topic: 48: com, twitpic, leave, school, add, pay, train, twitter, vip, www, thank, tweeteradder, right, nice, sorry\n",
      "Topic: 49: friend, bed, find, try, nice, rain, leave, help, play, tonight, suck, ready, tell, guy, morning\n",
      "Topic: 50: school, tweet, hope, sick, look, rain, tired, summer, feel, new, follow, bored, night, high, friend\n",
      "Topic: 51: nice, tweet, weekend, hope, feel, tomorrow, friend, long, enjoy, phone, way, weather, right, headache, twitter\n",
      "Topic: 52: tonight, tweet, week, com, way, oh, friend, hate, twitpic, tomorrow, leave, phone, hour, rain, later\n",
      "Topic: 53: tweet, tired, well, try, weekend, oh, find, school, long, sick, help, soon, friend, like, summer\n",
      "Topic: 54: tonight, try, leave, nice, tired, oh, school, thing, find, hour, people, hurt, suck, head, help\n",
      "Topic: 55: leave, well, hour, tweet, bed, soon, weekend, nice, school, hate, ready, bad, great, rain, new\n",
      "Topic: 56: oh, weekend, tired, follow, leave, hurt, suck, sick, friend, hour, start, well, long, guy, man\n",
      "Topic: 57: try, leave, weekend, hour, find, way, tired, help, long, feel, enjoy, night, hope, tomorrow, little\n",
      "Topic: 58: sick, weekend, suck, well, tonight, bed, school, try, long, tweet, eat, hurt, sleep, say, right\n",
      "Topic: 59: oh, leave, hour, hurt, sick, soon, great, head, tweet, nice, little, girl, look, try, fun\n",
      "Topic: 60: sick, tired, nice, hour, suck, well, leave, start, great, follow, tell, thing, movie, tomorrow, friend\n",
      "Topic: 61: hurt, head, suck, talk, movie, tummy, bored, throat, try, sun, phone, foot, find, stomach, eye\n",
      "Topic: 62: hour, find, suck, wake, people, early, life, talk, half, long, away, help, awesome, ago, headache\n",
      "Topic: 63: suck, try, soon, bed, enjoy, awesome, life, people, cold, year, eat, girl, ok, guess, lot\n",
      "Topic: 64: thing, let, life, long, suck, hurt, people, bored, talk, enjoy, guy, bed, lot, play, say\n",
      " Document First topic distribution: [ 0.07050695 -0.00313862 -0.00747535 -0.02525611  0.01643751  0.00826225\n",
      " -0.01916751 -0.00779845  0.0200709   0.00355469 -0.02173466 -0.04112808\n",
      " -0.01519533 -0.0854885   0.15985572 -0.01002226 -0.05286057  0.01686532\n",
      " -0.02025496  0.00676881  0.00749159  0.00978403  0.00961697 -0.01177582\n",
      " -0.01091036  0.02523407  0.01502215 -0.00303225  0.04145177 -0.02427696\n",
      "  0.04351241  0.03443751  0.00252267 -0.00167782  0.00794375  0.00066376\n",
      " -0.04228637 -0.00851642 -0.01748402  0.02978389  0.08055917  0.04071912\n",
      "  0.00866521 -0.00482395 -0.0139893   0.00034205 -0.00598491  0.03050494\n",
      "  0.00296888  0.15199644 -0.05280289 -0.04512017  0.03332311  0.03089053\n",
      "  0.02939565 -0.05674731 -0.03532266  0.03306782 -0.03152376 -0.04425128\n",
      "  0.0006707  -0.0012498   0.00193411 -0.00346615]\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "num_top_words = 15\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "for i, topic in enumerate(V_k):\n",
    "\n",
    "    top_indices = topic.argsort()[-num_top_words:][::-1]\n",
    "    top_words = [terms[index] for index in top_indices]\n",
    "    \n",
    "\n",
    "    print(f\"Topic: {i+1}: {', '.join(top_words)}\")\n",
    "\n",
    "\n",
    "document_topic_distribution  = U_k[1,:]\n",
    "print(f\" Document First topic distribution: {document_topic_distribution}\")\n",
    "print(len(document_topic_distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T06:05:45.429862Z",
     "iopub.status.busy": "2025-01-16T06:05:45.429423Z",
     "iopub.status.idle": "2025-01-16T06:05:45.438037Z",
     "shell.execute_reply": "2025-01-16T06:05:45.436927Z",
     "shell.execute_reply.started": "2025-01-16T06:05:45.429831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_df = np.array(V_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-09T04:23:16.947Z",
     "iopub.execute_input": "2025-01-09T04:22:57.379610Z",
     "iopub.status.busy": "2025-01-09T04:22:57.379224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# #A_k  =  U_k * S_k * V_k\n",
    "# A_k = np.dot(np.dot(U_k, S_k_diag), V_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T10:54:46.475792Z",
     "iopub.status.busy": "2025-01-08T10:54:46.475279Z",
     "iopub.status.idle": "2025-01-08T10:54:46.481208Z",
     "shell.execute_reply": "2025-01-08T10:54:46.479759Z",
     "shell.execute_reply.started": "2025-01-08T10:54:46.475753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_vectors =  V_k.T\n",
    "word_to_index = vectorizer.vocabulary_  #index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T10:55:02.275358Z",
     "iopub.status.busy": "2025-01-08T10:55:02.274945Z",
     "iopub.status.idle": "2025-01-08T10:55:02.282257Z",
     "shell.execute_reply": "2025-01-08T10:55:02.281099Z",
     "shell.execute_reply.started": "2025-01-08T10:55:02.275325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:04:22.969957Z",
     "iopub.status.busy": "2025-01-08T11:04:22.969539Z",
     "iopub.status.idle": "2025-01-08T11:04:22.990527Z",
     "shell.execute_reply": "2025-01-08T11:04:22.989118Z",
     "shell.execute_reply.started": "2025-01-08T11:04:22.969923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "\n",
    "for word, index in word_to_index.items():\n",
    "\n",
    "    index_to_word[index] = word\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:08:37.915233Z",
     "iopub.status.busy": "2025-01-08T11:08:37.914782Z",
     "iopub.status.idle": "2025-01-08T11:08:37.920496Z",
     "shell.execute_reply": "2025-01-08T11:08:37.919200Z",
     "shell.execute_reply.started": "2025-01-08T11:08:37.915187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " #Example: Get vector for a specific word\n",
    "word = \"example\"\n",
    "word_index = word_to_index[word]\n",
    "vector = word_vectors[word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:08:39.395082Z",
     "iopub.status.busy": "2025-01-08T11:08:39.394679Z",
     "iopub.status.idle": "2025-01-08T11:08:39.401128Z",
     "shell.execute_reply": "2025-01-08T11:08:39.400093Z",
     "shell.execute_reply.started": "2025-01-08T11:08:39.395050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3159"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T11:07:36.435916Z",
     "iopub.status.busy": "2025-01-08T11:07:36.435493Z",
     "iopub.status.idle": "2025-01-08T11:07:36.444471Z",
     "shell.execute_reply": "2025-01-08T11:07:36.443279Z",
     "shell.execute_reply.started": "2025-01-08T11:07:36.435882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.33154210e-04, -3.02649039e-04,  2.37097552e-04,  2.35383958e-04,\n",
       "       -1.66199202e-04,  3.46233588e-06,  6.24457738e-05, -5.93673345e-05,\n",
       "        1.67724744e-05, -1.43797639e-05,  1.33193757e-04,  8.29545024e-05,\n",
       "        5.91614674e-06,  5.70298681e-06, -4.38143883e-06, -1.94142186e-04,\n",
       "       -6.89824626e-05,  2.08339532e-05,  3.30724928e-05,  3.96527073e-04,\n",
       "        4.30015571e-05,  3.06636192e-05, -1.89400065e-07, -9.04715229e-05,\n",
       "       -1.37021803e-04, -2.41186193e-04, -1.72679985e-04, -6.26326591e-05,\n",
       "       -8.97852394e-05,  7.41388908e-06,  2.62658544e-04, -1.77423195e-04,\n",
       "        1.05992713e-05, -5.61983015e-05, -2.14315970e-05, -2.69773376e-05,\n",
       "       -2.84150043e-04, -2.82254523e-05, -3.43658711e-05,  2.69792687e-05,\n",
       "        2.40058764e-04, -1.41502084e-04, -3.12568911e-05,  2.52656853e-04,\n",
       "       -2.72973054e-05,  1.02369312e-05,  3.75508866e-04,  1.64255225e-04,\n",
       "       -2.51260364e-04, -2.14597960e-05, -2.63469674e-05, -3.54526849e-05,\n",
       "       -2.57629340e-05,  1.93474816e-04,  5.90911348e-05, -5.53542002e-05,\n",
       "       -7.43836567e-05, -1.00366409e-04, -1.04415715e-04, -2.89064177e-05,\n",
       "        1.51847507e-04, -5.44708235e-05, -2.77017038e-05, -1.93475208e-04])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2477,
     "sourceId": 4140,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6427175,
     "sourceId": 10375914,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6437609,
     "sourceId": 10391179,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6437683,
     "sourceId": 10391276,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
